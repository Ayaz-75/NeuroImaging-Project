{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Research-Grade Neuroimaging with Machine Learning & Deep Learning\n",
        "\n",
        "**Instructor:** Ayaz Ali  \n",
        "**Platform:** Google Colab  \n",
        "**Domain:** Structural MRI  \n",
        "**Level:** Research / PhD-ready\n",
        "\n",
        "---\n",
        "\n",
        "## Workshop Objectives\n",
        "- Understand neuroimaging as a **population-level ML problem**\n",
        "- Build a **proper ML baseline**\n",
        "- Train a **3D CNN on volumetric MRI**\n",
        "- Follow **real research best practices**\n",
        "- Understand how this maps to **ADNI / OpenNeuro**\n"
      ],
      "metadata": {
        "id": "G5ZV2J5psLzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Neuroimaging as a Research Problem\n",
        "\n",
        "Key principles:\n",
        "\n",
        "- **One subject = one sample**\n",
        "- Each subject has a **3D brain volume**\n",
        "- Labels come from **clinical diagnosis**\n",
        "- Models learn **population-level patterns**\n",
        "\n",
        "üö´ We never train ML models on a single brain.\n"
      ],
      "metadata": {
        "id": "RDOUj1f1BRrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install nibabel nilearn torch torchvision scikit-learn matplotlib --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg8zPCO1sI5N",
        "outputId": "27e4e95b-fe2b-4c10-e30b-214ea39b6b79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Dataset Design (Research Standard)\n",
        "\n",
        "For teaching, we **simulate** a dataset:\n",
        "\n",
        "- 100 subjects\n",
        "- Each subject has a 3D MRI (32√ó32√ó32)\n",
        "- Binary classification:\n",
        "  - 0 ‚Üí Healthy\n",
        "  - 1 ‚Üí Disease\n",
        "\n",
        "‚ö†Ô∏è Pipeline is identical to real MRI datasets."
      ],
      "metadata": {
        "id": "CoPoCxnws4oP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "N_SUBJECTS = 100\n",
        "IMG_SHAPE = (32, 32, 32)\n",
        "\n",
        "# Simulated MRI volumes\n",
        "X = np.random.rand(N_SUBJECTS, *IMG_SHAPE)\n",
        "\n",
        "# Balanced binary labels\n",
        "y = np.array([0]*50 + [1]*50)\n",
        "\n",
        "print(\"MRI dataset shape:\", X.shape)\n",
        "print(\"Label distribution:\", np.bincount(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDbeZrkQs-j2",
        "outputId": "9c43e36e-504c-404f-e648-3ded4029cff2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRI dataset shape: (100, 32, 32, 32)\n",
            "Label distribution: [50 50]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train / Validation Split\n",
        "\n",
        "This is **mandatory in real research**.\n",
        "No evaluation on training data.\n"
      ],
      "metadata": {
        "id": "E-_nUt6Ht1Ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train subjects:\", X_train.shape[0])\n",
        "print(\"Validation subjects:\", X_val.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYT07LOotGW3",
        "outputId": "9ade9240-9fd5-4cd4-b834-4aa3137287d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train subjects: 80\n",
            "Validation subjects: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Classical Machine Learning Baseline\n",
        "\n",
        "Why we do this:\n",
        "- Reviewers expect a **baseline**\n",
        "- Shows why deep learning is needed\n",
        "- Establishes a reference point\n"
      ],
      "metadata": {
        "id": "VYpkJ_0huEMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Flatten 3D MRI ‚Üí feature vector\n",
        "X_train_flat = X_train.reshape(len(X_train), -1)\n",
        "X_val_flat = X_val.reshape(len(X_val), -1)\n",
        "\n",
        "clf = LogisticRegression(max_iter=2000)\n",
        "clf.fit(X_train_flat, y_train)\n",
        "\n",
        "val_preds = clf.predict(X_val_flat)\n",
        "val_acc = accuracy_score(y_val, val_preds)\n",
        "\n",
        "print(\"Validation Accuracy (ML Baseline):\", val_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ouk7a7VUt-GB",
        "outputId": "5295d77d-d3e3-4f9b-bff3-7219df018f6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (ML Baseline): 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Why Deep Learning?\n",
        "\n",
        "Flattening destroys:\n",
        "- Spatial locality\n",
        "- Anatomical structure\n",
        "\n",
        "CNNs learn:\n",
        "- Local patterns\n",
        "- Hierarchical brain features\n",
        "\n",
        "Next: **3D CNN on volumetric MRI**\n"
      ],
      "metadata": {
        "id": "pVj2w_5NuUP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X).float().unsqueeze(1)  # (N, 1, D, H, W)\n",
        "        self.y = torch.tensor(y).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_ds = MRIDataset(X_train, y_train)\n",
        "val_ds = MRIDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=8)\n"
      ],
      "metadata": {
        "id": "C9O0T2ISuQUK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 3D Convolutional Neural Network\n",
        "\n",
        "This is **true neuroimaging deep learning**:\n",
        "- 3D convolutions\n",
        "- Volumetric feature learning\n"
      ],
      "metadata": {
        "id": "PYXpKTsDvEeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CNN3D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv3d(1, 8, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(2),\n",
        "\n",
        "            nn.Conv3d(8, 16, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(16 * 6 * 6 * 6, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "model = CNN3D()\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1BSfYqMuZKh",
        "outputId": "c962c516-f230-45b5-a0e8-7d19c8401c0e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN3D(\n",
            "  (features): Sequential(\n",
            "    (0): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Linear(in_features=3456, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Training Loop (Research Practice)\n",
        "\n",
        "- GPU support\n",
        "- Separate training & validation\n",
        "- Cross-entropy loss\n"
      ],
      "metadata": {
        "id": "ZKuhVr5EvUSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(xb)\n",
        "        loss = criterion(outputs, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {total_loss:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIIgZx7OvWGF",
        "outputId": "040b6e71-4a2c-4e54-c1f9-813e8958c52e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Train Loss: 7.244\n",
            "Epoch 2/5 | Train Loss: 6.940\n",
            "Epoch 3/5 | Train Loss: 6.925\n",
            "Epoch 4/5 | Train Loss: 6.883\n",
            "Epoch 5/5 | Train Loss: 6.855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Validation Evaluation\n",
        "\n",
        "Evaluation is done on **unseen subjects**.\n"
      ],
      "metadata": {
        "id": "Cct5H6GVve5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        outputs = model(xb)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "\n",
        "print(\"Validation Accuracy (3D CNN):\", correct / total)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX3OF4TQvblA",
        "outputId": "1380e146-1061-4eb3-c55b-c8d5a2a8ed0e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (3D CNN): 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Research Extensions (PhD-Level)\n",
        "\n",
        "You can now extend this to:\n",
        "\n",
        "- Real MRI loading (NiBabel + NIfTI)\n",
        "- Intensity normalization\n",
        "- Skull stripping\n",
        "- Transfer learning\n",
        "- Explainable AI (Grad-CAM)\n",
        "- fMRI time-series (LSTM / Transformers)\n",
        "- Graph Neural Networks (connectomes)\n",
        "\n",
        "This notebook now follows **real neuroimaging research standards**.\n"
      ],
      "metadata": {
        "id": "x_AmEW5yvtmK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ufMBlDMsvnmY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eZMnORTevyTh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}